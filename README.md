# ğŸ“„ Chat with PDF - Hybrid Search using Haystack & Streamlit

## ğŸš€ Project Overview
This project enables users to **upload PDFs** and **ask questions** about their content using a **Hybrid Retrieval-Augmented Generation (RAG)** pipeline. It integrates:

- **SentenceTransformersTextEmbedder** for text embedding
- **PineconeEmbeddingRetriever** for vector-based document retrieval
- **GoogleAIGeminiGenerator** for AI-powered responses
- **Streamlit UI** for user interaction

## ğŸ›  Tech Stack
- **Python** (FastAPI + Streamlit)
- **Haystack** (NLP pipeline)
- **Pinecone** (Vector database for document storage & retrieval)
- **Google AI Gemini** (LLM-based response generation)
- **Jinja2** (Prompt templating)

---

## ğŸ“Œ Features
âœ… Upload a **PDF document** and ask questions about it.
âœ… **Hybrid Retrieval**: Uses **vector search** and **semantic similarity**.
âœ… **Dynamic Jinja2 Prompts** for better LLM responses.
âœ… **Session-based Cleanup**: Deletes user data after session ends.
âœ… **Error Handling & Debugging**: Logs retrieval steps for easy troubleshooting.

---

## ğŸ“‚ Project Structure
```
ğŸ“ QASystem
 â”£ ğŸ“‚ utils
 â”ƒ â”— ğŸ“„ pinecone_configuration.py  # Pinecone DB setup
 â”£ ğŸ“„ app.py  # Main Streamlit app
 â”£ ğŸ“„ requirements.txt  # Dependencies
 â”£ ğŸ“„ .env  # API Keys & Secrets
 â”— ğŸ“„ README.md  # Documentation
```

---

## ğŸ— Installation & Setup
### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/Warishayat/Hybrid-Rag-Search-Haystack
cd chat-with-pdf
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirement.txt
```

### 4ï¸âƒ£ Set Up Environment Variables
Create a **.env** file and add:
```ini
PINECONE_API_KEY=your_pinecone_api_key
GEMINI_API_KEY=your_google_ai_gemini_api_key
HF_API_TOKEN=your_huggingface_api_token
```

---

## ğŸš€ Run the Application
```bash
streamlit run main.py
```

---

## ğŸ›  API Flow
1. **Upload PDF** â†’ Extracts text & stores embeddings in **Pinecone**.
2. **User Query** â†’ Gets transformed into an **embedding**.
3. **Retriever** â†’ Searches for similar document chunks.
4. **Jinja2 Prompt Builder** â†’ Structures the query context.
5. **Google AI Gemini** â†’ Generates the final response.
6. **Streamlit UI** â†’ Displays the answer.

---


## ğŸ›  Troubleshooting
- **"No response from the model"** â†’ Check if API keys are correct.
- **"PDF uploaded successfully but no result"** â†’ Ensure embeddings are being stored in Pinecone.
- **Debugging Retrieval** â†’ Add `print(retrieved_docs)` in `get_response()` to check document retrieval.

---

## ğŸ“ Future Improvements
ğŸ”¹ Add support for **multiple PDFs** in a single query.  
ğŸ”¹ Improve **response ranking** for better relevance.  
ğŸ”¹ Integrate **local LLMs** (Mistral, Llama 3) instead of cloud-based AI.  

---

## ğŸ¤ Contributing
Pull requests are welcome! Feel free to improve the code and submit changes.

---
